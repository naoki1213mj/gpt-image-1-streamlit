from __future__ import annotations

# GPT-image-1 Streamlit â€“ Easy Authï¼†ãƒ­ãƒ¼ã‚«ãƒ«ä¸¡å¯¾å¿œï¼ˆtxt2img / img2imgï¼‰
import base64
import io
import logging
import os
import time
from dataclasses import dataclass
from enum import Enum
from typing import Any, Dict, List, Optional, Tuple

import dotenv
import requests
import streamlit as st
from openai import AzureOpenAI, OpenAI
from PIL import Image
import dotenv
import requests
import streamlit as st
from openai import AzureOpenAI, OpenAI
from PIL import Image

# GPT-image-1 Streamlit â€“ Easy Authï¼†ãƒ­ãƒ¼ã‚«ãƒ«ä¸¡å¯¾å¿œï¼ˆtxt2img / img2imgï¼‰


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒªãƒˆãƒ©ã‚¤è¨­å®šï¼ˆãƒãƒ¼ã‚¸ãƒ§ãƒ³å·®ç•°å¯¾ç­–ï¼‰
try:
    from openai import RetryConfig  # v1.17â€“1.75
except ImportError:
    try:
        from openai._types import RetryConfig  # v1.76+
    except ImportError:
        RetryConfig = None  # ã•ã‚‰ã«å¤ã„ï¼æ–°ã—ã„å ´åˆ

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
IMAGE_LONG_EDGE_MAX = 2048
HISTORY_MAX = 30
TIMEOUT_SEC = 300  # httpx / requests ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class ImageSize(str, Enum):
    AUTO = "auto"
    SQUARE = "1024x1024"
    LANDSCAPE = "1536x1024"
    PORTRAIT = "1024x1536"


class ImageFormat(str, Enum):
    PNG = "png"
    JPEG = "jpeg"
    WEBP = "webp"


class ImageQuality(str, Enum):
    AUTO = "auto"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"


class Background(str, Enum):
    AUTO = "auto"
    TRANSPARENT = "transparent"
    OPAQUE = "opaque"


class Moderation(str, Enum):
    AUTO = "auto"
    LOW = "low"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@dataclass(frozen=True)
class Config:
    azure_deployment: Optional[str]
    azure_endpoint: Optional[str]
    azure_key: Optional[str]
    azure_api_version: str
    openai_key: Optional[str]
    log_level: str
    easy_auth: bool

    @classmethod
    def from_env(cls) -> "Config":
        dotenv.load_dotenv(override=False)
        return cls(
            azure_deployment=os.getenv("AZURE_OPENAI_API_IMAGE_MODEL"),
            azure_endpoint=os.getenv("AZURE_OPENAI_API_IMAGE_ENDPOINT"),
            azure_key=os.getenv("AZURE_OPENAI_API_IMAGE_KEY") or os.getenv("AZURE_OPENAI_API_KEY"),
            azure_api_version=os.getenv("AZURE_OPENAI_API_VERSION", "2024-02-01"),
            openai_key=os.getenv("OPENAI_API_KEY"),
            log_level=os.getenv("LOG_LEVEL", "INFO"),
            easy_auth=os.getenv("EASY_AUTH_ENABLED", "false").lower() == "true",
        )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class Auth:
    @staticmethod
    def _secrets_ready() -> bool:
        try:
            return bool(st.secrets["auth"]["microsoft"]["client_id"])
        except Exception:
            return False

    @staticmethod
    def ensure(cfg: Config) -> None:
        if cfg.easy_auth:
            return
        if not Auth._secrets_ready():
            st.warning(".streamlit/secrets.toml ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã®ã§èªè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
            return
        if not getattr(st.user, "is_logged_in", False):
            st.login("microsoft")
            st.stop()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class AIClient:
    def __init__(self, cfg: Config) -> None:
        logging.basicConfig(level=cfg.log_level.upper())
        self.cfg = cfg
        common: Dict[str, Any] = {"timeout": TIMEOUT_SEC}
        if RetryConfig:
            common["retry_config"] = RetryConfig(max_retries=5, min_seconds=1, max_seconds=20)

        if cfg.azure_endpoint and cfg.azure_key:
            self.client = AzureOpenAI(
                azure_endpoint=cfg.azure_endpoint,
                api_key=cfg.azure_key,
                api_version=cfg.azure_api_version,
                **common,
            )
            self.model = cfg.azure_deployment or "gpt-image-1"
            self.is_azure = True
        else:
            if not cfg.openai_key:
                raise RuntimeError("OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            self.client = OpenAI(api_key=cfg.openai_key, **common)
            self.model = "gpt-image-1"
            self.is_azure = False

    # ---- ã‚µã‚¤ã‚ºåˆ¶é™
    @staticmethod
    def _cap(img: Image.Image) -> Image.Image:
        if max(img.size) > IMAGE_LONG_EDGE_MAX:
            img.thumbnail((IMAGE_LONG_EDGE_MAX, IMAGE_LONG_EDGE_MAX))
        return img

    # ---- txt2img
    def generate(
        self, *, prompt: str, background: str, moderation: str, compression: int, fmt: str, quality: str, size: str
    ) -> Tuple[Image.Image, Dict[str, Any]]:
        t0 = time.time()
        rsp = self.client.images.generate(
            prompt=prompt,
            model=self.model,
            n=1,
            background=background,
            moderation=moderation,
            output_compression=compression,
            output_format=fmt,
            quality=quality,
            size=size,
        )
        img = self._cap(Image.open(io.BytesIO(base64.b64decode(rsp.data[0].b64_json))))
        meta = dict(
            prompt=prompt,
            settings=dict(
                background=background,
                moderation=moderation,
                compression=compression,
                format=fmt,
                quality=quality,
                size=size,
            ),
            generation_time=round(time.time() - t0, 2),
            timestamp=time.strftime("%Y-%m-%d %H:%M:%S"),
            type="text-to-image",
        )
        return img, meta

    # ---- img2img
    def edit(self, image_bytes: bytes, *, prompt: str, quality: str, size: str) -> Tuple[Image.Image, Dict[str, Any]]:
        t0 = time.time()
        if self.is_azure:
            url = f"{self.cfg.azure_endpoint}/openai/deployments/{self.model}/images/edits?api-version={self.cfg.azure_api_version}"
            hdr = {"api-key": self.cfg.azure_key}
            data = {"prompt": prompt, "model": "gpt-image-1", "size": size, "n": 1, "quality": quality}
            files = {"image": ("image.png", image_bytes, "image/png")}
            rsp = requests.post(url, headers=hdr, data=data, files=files, timeout=TIMEOUT_SEC)
            if rsp.status_code != 200:
                raise RuntimeError(f"Azure edit å¤±æ•—: {rsp.status_code} {rsp.text}")
            b64 = rsp.json()["data"][0]["b64_json"]
        else:
            rsp = self.client.images.edit(
                model=self.model, image=image_bytes, prompt=prompt, n=1, quality=quality, size=size
            )
            b64 = rsp.data[0].b64_json
        img = self._cap(Image.open(io.BytesIO(base64.b64decode(b64))))
        meta = dict(
            prompt=prompt,
            settings=dict(quality=quality, size=size),
            generation_time=round(time.time() - t0, 2),
            timestamp=time.strftime("%Y-%m-%d %H:%M:%S"),
            type="image-to-image",
        )
        return img, meta


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class UI:
    @staticmethod
    def setup():
        st.set_page_config("GPT-Image-1 Generator", "ğŸ–¼ï¸", layout="wide")
        css = "static/theme.css"
        if os.path.exists(css):
            st.markdown(f"<style>{open(css).read()}</style>", unsafe_allow_html=True)

    @staticmethod
    def header():
        c1, c2 = st.columns([9, 1])
        c1.markdown("## âœ¨ GPT-image-1 ç”»åƒã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼")
        if getattr(st, "user", None) and getattr(st.user, "name", None):
            c2.markdown(
                f"<span style='font-size:0.9rem;color:#94a3b8;'>ğŸ‘¤ {st.user.name}</span>", unsafe_allow_html=True
            )
        if getattr(st.user, "is_logged_in", False):
            c2.button(
                "ğŸ”’ ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ", on_click=st.logout, key="logout_btn", help="ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹å ´åˆã¯ã“ã¡ã‚‰ã‹ã‚‰"
            )
        st.divider()

    # ---------- ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ« ----------
    @staticmethod
    def _tutorial_body():
        st.markdown("### ã‚ˆã†ã“ãï¼ ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰")
        st.write("- **ãƒ¢ãƒ¼ãƒ‰åˆ‡æ›¿** ã§ txt2img / img2img ã‚’é¸æŠ")
        st.write("- ã‚µãƒ³ãƒ—ãƒ«ãƒœã‚¿ãƒ³ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ¯ãƒ³ã‚¿ãƒƒãƒæŒ¿å…¥")
        st.write("- âš™ï¸ è©³ç´°è¨­å®š ã§èƒŒæ™¯ / å“è³ª / ã‚µã‚¤ã‚ºã‚’èª¿æ•´")
        st.write("- ç”Ÿæˆãƒ»ç·¨é›†ã—ãŸç”»åƒã¯ã‚®ãƒ£ãƒ©ãƒªãƒ¼ã«è‡ªå‹•ä¿å­˜")
        if st.button("ã¯ã˜ã‚ã‚‹", key="tut_close"):
            st.session_state["tutorial_shown"] = True
            st.rerun()

    @staticmethod
    def _show_expander_fallback():
        """æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆExpanderï¼‰"""
        with st.expander("ğŸ“ åˆå›ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«", expanded=True):
            UI._tutorial_body()

    @staticmethod
    def tutorial_modal():
        if st.session_state.get("tutorial_shown"):
            return

        # 1) experimental_dialog ãŒå­˜åœ¨ã™ã‚‹ã‹ï¼Ÿ
        if hasattr(st, "experimental_dialog"):
            dlg_obj = st.experimental_dialog  # 1.25â€“ ã¯ decorator / 1.34â€“ ã¯ context manager
            # context-manager ã‹ã©ã†ã‹åˆ¤å®š
            if callable(dlg_obj) and not hasattr(dlg_obj, "__enter__"):
                # decorator å½¢å¼ã®ã¿ â†’ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                UI._show_expander_fallback()
            else:
                with st.experimental_dialog("ğŸ“ åˆå›ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«"):
                    UI._tutorial_body()
            return

        # 2) dialog ãŒå­˜åœ¨ã™ã‚‹ã‹ï¼Ÿ
        if hasattr(st, "dialog"):
            dlg_obj = st.dialog
            if callable(dlg_obj) and not hasattr(dlg_obj, "__enter__"):
                # decorator å½¢å¼ã®ã¿
                UI._show_expander_fallback()
            else:
                with st.dialog("ğŸ“ åˆå›ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«"):
                    UI._tutorial_body()
            return

        # 3) ã©ã¡ã‚‰ã‚‚ç„¡ã„ â†’ Expander
        UI._show_expander_fallback()

    @staticmethod
    def add_hist(img: Image.Image, meta: Dict[str, Any]):
        hist = st.session_state.setdefault("history", [])
        hist.insert(0, dict(image=img, meta=meta, id=str(time.time())))
        if len(hist) > HISTORY_MAX:
            hist[:] = hist[:HISTORY_MAX]

    @staticmethod
    def gallery():
        hist = st.session_state.get("history", [])
        if not hist:
            return
        st.markdown("### ğŸ–¼ï¸ ç”Ÿæˆå±¥æ­´")
        for tag, title in [("all", "ã™ã¹ã¦"), ("txt", "ãƒ†ã‚­ã‚¹ãƒˆâ†’ç”»åƒ (txt2img)"), ("img", "ç”»åƒâ†’ç”»åƒ (img2img)")]:
            subset = (
                hist
                if tag == "all"
                else [h for h in hist if h["meta"]["type"].startswith("text" if tag == "txt" else "image")]
            )
            st.markdown(f"#### {title}")
            UI._gal_items(subset, tag)

    @staticmethod
    def _gal_items(items: List[Dict], tag: str):
        cols = st.columns(3)
        for i, it in enumerate(items):
            with cols[i % 3]:
                buf = io.BytesIO()
                it["image"].save(buf, format="PNG")
                st.image(it["image"], use_container_width=True)
                st.download_button(
                    "ğŸ’¾ ä¿å­˜",
                    buf.getvalue(),
                    file_name=f"{it['id']}.png",
                    mime="image/png",
                    key=f"dl_{tag}_{it['id']}_{i}",
                    help="PNGå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    use_container_width=True,
                )

    # ---- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼†ã‚¹ã‚¿ã‚¤ãƒ«ä¾‹
    PROMPTS = {
        "é¢¨æ™¯": "å±±é ‚ã‹ã‚‰è¦‹ã‚‹é›„å¤§ãªæ™¯è‰²ã€æœæ—¥ãŒé›²æµ·ã‚’ç…§ã‚‰ã™ã€é›ªã‚’ã‹ã¶ã£ãŸå±±ã€…",
        "éƒ½å¸‚": "å¤œã®æ±äº¬ã€ãƒã‚ªãƒ³ã¨é›¨ã€ã‚µã‚¤ãƒãƒ¼ãƒ‘ãƒ³ã‚¯ã‚¹ã‚¿ã‚¤ãƒ«",
        "ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼": "ãƒ‰ãƒ©ã‚´ãƒ³ãŒé£›ã¶é­”æ³•ã®æ£®ã€ç¥ç§˜çš„ãªå…‰ã€å¹»æƒ³çš„ãªä¸–ç•Œ",
        "å’Œé¢¨": "æ—¥æœ¬ã®ä¼çµ±çš„ãªåº­åœ’ã€ç´…è‘‰ã€è‹”ã‚€ã—ãŸçŸ³ç¯ç± ",
        "é£Ÿã¹ç‰©": "ç¾å‘³ã—ãã†ãªå’Œé£Ÿã®å®šé£Ÿã€æ¸©ã‹ã¿ã®ã‚ã‚‹ç…§æ˜",
        "ã‚¢ãƒ‹ãƒ¡": "ã‚¸ãƒ–ãƒªé¢¨ã®ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼ä¸–ç•Œã€è‹¥ã„å†’é™ºè€…",
        "æœªæ¥": "2150å¹´ã®éƒ½å¸‚ã€ç©ºé£›ã¶è»Šã€ãƒ›ãƒ­ã‚°ãƒ©ãƒ åºƒå‘Š",
        "ãƒãƒ¼ãƒˆãƒ¬ãƒ¼ãƒˆ": "è‡ªç„¶å…‰ã§ç…§ã‚‰ã•ã‚ŒãŸå¥³æ€§ã®è‚–åƒã€èƒŒæ™¯ãƒœã‚±",
    }
    STYLES = {
        "ã‚¸ãƒ–ãƒª": "ã‚¸ãƒ–ãƒªé¢¨ã®ã‚¢ãƒ‹ãƒ¡ã‚¹ã‚¿ã‚¤ãƒ«ã«å¤‰æ›",
        "æ°´å½©ç”»": "ç¹Šç´°ãªæ°´å½©ç”»ã‚¹ã‚¿ã‚¤ãƒ«ã«å¤‰æ›",
        "æ²¹çµµ": "å°è±¡æ´¾ã®æ²¹çµµã‚¹ã‚¿ã‚¤ãƒ«ã«å¤‰æ›",
        "æ¼«ç”»": "æ—¥æœ¬ã®æ¼«ç”»é¢¨ã‚¤ãƒ©ã‚¹ãƒˆã«å¤‰æ›",
        "ãƒã‚ªãƒ³": "ã‚µã‚¤ãƒãƒ¼ãƒ‘ãƒ³ã‚¯é¢¨ã«ãƒã‚ªãƒ³ã‚«ãƒ©ãƒ¼ã§å¼·èª¿",
        "å¤•æš®ã‚Œ": "å¤•æš®ã‚Œã®æ¸©ã‹ã„ã‚ªãƒ¬ãƒ³ã‚¸è‰²ã«å¤‰æ›´",
        "å†¬æ™¯è‰²": "é›ªæ™¯è‰²ã«å¤‰æ›´",
        "ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼": "é­”æ³•ã®ä¸–ç•Œé¢¨ã«å¤‰æ›´",
    }

    @staticmethod
    def prompt_examples():
        st.markdown("##### ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹")
        cols = st.columns(4)
        for i, (k, v) in enumerate(UI.PROMPTS.items()):
            with cols[i % 4]:
                if st.button(k, key=f"prom_{k}", help="ã‚¯ãƒªãƒƒã‚¯ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã‚³ãƒ”ãƒ¼"):
                    st.session_state["txt_prompt_tmp"] = v
                    st.rerun()

    @staticmethod
    def style_examples():
        st.markdown("##### ğŸ¨ ã‚¹ã‚¿ã‚¤ãƒ«ä¾‹")
        cols = st.columns(4)
        for i, (k, v) in enumerate(UI.STYLES.items()):
            with cols[i % 4]:
                if st.button(k, key=f"style_{k}", help="ã‚¯ãƒªãƒƒã‚¯ã§ç·¨é›†ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã‚³ãƒ”ãƒ¼"):
                    st.session_state["img_prompt_tmp"] = v
                    st.rerun()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    cfg = Config.from_env()
    Auth.ensure(cfg)
    UI.setup()
    ai = AIClient(cfg)
    UI.header()
    UI.tutorial_modal()

    mode = st.radio(
        "æ“ä½œãƒ¢ãƒ¼ãƒ‰",
        ["ãƒ†ã‚­ã‚¹ãƒˆâ†’ç”»åƒ(txt2img)", "ç”»åƒâ†’ç”»åƒ(img2img)"],
        horizontal=True,
        help="ç”Ÿæˆæ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„",
    )
    st.divider()

    # ======== ãƒ†ã‚­ã‚¹ãƒˆâ†’ç”»åƒ ========
    if mode.startswith("ãƒ†ã‚­ã‚¹ãƒˆ"):
        default_val = st.session_state.pop("txt_prompt_tmp", st.session_state.get("txt_prompt", ""))
        prompt = st.text_area(
            "âœï¸ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
            key="txt_prompt",
            value=default_val,
            height=120,
            placeholder="ä¾‹: A neon cyber-punk skyline at dusk, flying cars, holographic billboardsâ€¦",
            help="ç”Ÿæˆã—ãŸã„ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ã§ãã‚‹ã ã‘å…·ä½“çš„ã«å…¥åŠ›ã—ã¦ãã ã•ã„",
        )
        UI.prompt_examples()

        with st.expander("âš™ï¸ è©³ç´°è¨­å®š", expanded=False):
            c1, c2 = st.columns(2)
            with c1:
                bg = st.selectbox(
                    "èƒŒæ™¯", [e.value for e in Background], key="bg", help="èƒŒæ™¯ã®é€æ˜ï¼ä¸é€æ˜ãªã©ã‚’æŒ‡å®šã—ã¾ã™"
                )
                mod = st.selectbox(
                    "ãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³", [e.value for e in Moderation], key="mod", help="ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®å¼·ã•"
                )
            with c2:
                qual = st.selectbox(
                    "å“è³ª", [e.value for e in ImageQuality], key="qual", help="é«˜å“è³ªã»ã©å‡¦ç†æ™‚é–“ãŒé•·ããªã‚Šã¾ã™"
                )
                fmt = st.selectbox(
                    "ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ", [e.value for e in ImageFormat], key="fmt", help="é€éãŒå¿…è¦ãªã‚‰ PNG æ¨å¥¨"
                )
            comp = st.slider(
                "åœ§ç¸®ç‡ (JPEG/WebP)",
                0,
                100,
                100,
                key="comp",
                disabled=(fmt == "png"),
                help="æ•°å€¤ã‚’ä¸‹ã’ã‚‹ã»ã©é«˜åœ§ç¸® (ä½ç”»è³ª) ã«ãªã‚Šã¾ã™",
            )
            size = st.selectbox(
                "ã‚µã‚¤ã‚º", [e.value for e in ImageSize], key="size", help="auto ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…å®¹ã‚’ã‚‚ã¨ã«è‡ªå‹•ã§åˆ¤å®š"
            )

        if st.button("ğŸš€ ç”»åƒç”Ÿæˆ", type="primary", use_container_width=True, help="æŒ‡å®šå†…å®¹ã§ç”»åƒã‚’ç”Ÿæˆ"):
            txt = st.session_state["txt_prompt"].strip()
            if not txt:
                st.warning("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            else:
                prog = st.progress(0, "ç”Ÿæˆä¸­â€¦")
                img, meta = ai.generate(
                    prompt=txt, background=bg, moderation=mod, compression=comp, fmt=fmt, quality=qual, size=size
                )
                prog.progress(100, "å®Œäº†")
                st.image(img, use_container_width=True, caption=f"{meta['generation_time']}ç§’")
                UI.add_hist(img, meta)
                st.balloons()

    # ======== ç”»åƒâ†’ç”»åƒ ========
    else:
        c1, c2 = st.columns([1, 1])
        with c1:
            up = st.file_uploader(
                "å…¥åŠ›ç”»åƒ",
                type=["png", "jpg", "jpeg"],
                key="up",
                accept_multiple_files=False,
                help="ç·¨é›†ã—ãŸã„å…ƒç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
            )
            default_val = st.session_state.pop("img_prompt_tmp", st.session_state.get("img_prompt", ""))
            pr = st.text_area(
                "âœï¸ ç·¨é›†ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
                key="img_prompt",
                value=default_val,
                height=100,
                placeholder="ä¾‹: ã‚¸ãƒ–ãƒªé¢¨ã®æ¸©ã‹ã„ã‚¢ãƒ‹ãƒ¡ã‚¹ã‚¿ã‚¤ãƒ«ã«å¤‰æ›â€¦",
                help="â†‘ãƒœã‚¿ãƒ³ã§ã‚¹ã‚¿ã‚¤ãƒ«ä¾‹ã‚’ã‚³ãƒ”ãƒ¼ã§ãã¾ã™",
            )
            UI.style_examples()
            with st.expander("âš™ï¸ è©³ç´°è¨­å®š", expanded=False):
                qual = st.selectbox("å“è³ª", [e.value for e in ImageQuality], key="e_qual", help="å‡ºåŠ›ç”»åƒã®å“è³ª")
                size = st.selectbox(
                    "ã‚µã‚¤ã‚º", [e.value for e in ImageSize], key="e_size", help="å…ƒç”»åƒæ¯”ã§å¤‰å½¢ãŒèµ·ã“ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™"
                )
            edit = st.button(
                "ğŸ–Œï¸ ç”»åƒç·¨é›†", type="primary", use_container_width=True, help="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»åƒã‚’æŒ‡å®šã‚¹ã‚¿ã‚¤ãƒ«ã§å†ç”Ÿæˆ"
            )

        with c2:
            if up:
                prev = Image.open(up)
                st.image(prev, use_container_width=True, caption="å…¥åŠ›ç”»åƒ")
                with st.expander("ğŸ“Š ç”»åƒæƒ…å ±", expanded=False):
                    w, h = prev.size
                    fmt0 = prev.format or "?"
                    st.write(f"**ã‚µã‚¤ã‚º:** {w}Ã—{h}")
                    st.write(f"**å½¢å¼:** {fmt0}")
                    st.write(f"**å®¹é‡:** {len(up.getvalue())/1024:.1f} KB")

        if edit:
            if not up:
                st.warning("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
                st.stop()
            txt = st.session_state["img_prompt"].strip()
            if not txt:
                st.warning("ç·¨é›†ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                st.stop()
            prog = st.progress(0, "ç·¨é›†ä¸­â€¦")
            img, meta = ai.edit(up.getvalue(), prompt=txt, quality=qual, size=size)
            prog.progress(100, "å®Œäº†")
            a, b = st.columns(2)
            a.image(prev, use_container_width=True, caption="ç·¨é›†å‰")
            b.image(img, use_container_width=True, caption=f"ç·¨é›†å¾Œ ({meta['generation_time']}ç§’)")
            UI.add_hist(img, meta)
            st.balloons()

    UI.gallery()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    main()
